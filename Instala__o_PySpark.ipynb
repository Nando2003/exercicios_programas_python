{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ltP7wPreyLhz",
        "nBZ5rch4y66d",
        "z7I3-UI0zQF9",
        "_ZHxxkvK0SLF",
        "7EN_zAHi3jZv",
        "2rKsJzv652Sd",
        "2meb5_T29Fj_",
        "TZq_hLfT-I3L",
        "IlwoLni8-jRd"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nando2003/exercicios_programas_python/blob/main/Instala__o_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação do PySpark"
      ],
      "metadata": {
        "id": "WwUdF_I6va-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando o Java 8"
      ],
      "metadata": {
        "id": "nnMvLCYOvhKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "LFVX1aHSvkNa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baixando spark"
      ],
      "metadata": {
        "id": "PbSwDwmJwuSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "4DKR86Ksw0nT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descompatacando o spark"
      ],
      "metadata": {
        "id": "ltP7wPreyLhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "u7TEDpVTyM_s"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando o findspark"
      ],
      "metadata": {
        "id": "nBZ5rch4y66d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "OTBezr5py-Nk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando o pyspark\n"
      ],
      "metadata": {
        "id": "z7I3-UI0zQF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark"
      ],
      "metadata": {
        "id": "JlBqh2LJzTYc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definindo as variáveis de ambiente"
      ],
      "metadata": {
        "id": "_ZHxxkvK0SLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.1.2-bin-hadoop2.7'"
      ],
      "metadata": {
        "id": "r-qD7vyH0V40"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iniciando o spark"
      ],
      "metadata": {
        "id": "7EN_zAHi3jZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "eQSIekl93k3W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Frame"
      ],
      "metadata": {
        "id": "nyxbfp-onqBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CRIANDO** **UMA** **SESSÃO**"
      ],
      "metadata": {
        "id": "H5nj6KtKxTls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        ".master('local[*]')\\\n",
        ".appName('Dataframes com spark')\\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "-uyqWl4Qnj17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CRIANDO** **DATA** **FRAME**\n",
        "\n"
      ],
      "metadata": {
        "id": "LWfeaE2HxOv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meus_produtos = [\n",
        "    {'ID': 1, 'Produto': 'Notebook', 'Fabricante': 'Dell', 'Garantia': '2030-05-04', 'Valor': '4200,99'},\n",
        "    {'ID': 2, 'Produto': 'Monitor', 'Fabricante': 'Dell', 'Garantia': '2030-05-04', 'Valor': '750,29'},\n",
        "    {'ID': 3, 'Produto': 'Memoria Ram 16GB', 'Fabricante': 'Dell', 'Garantia': '2030-05-04', 'Valor': '200,00'},\n",
        "    {'ID': 4, 'Produto': 'Teclado', 'Fabricante': 'Dell', 'Garantia': '2030-05-04', 'Valor': '350,27'},\n",
        "    {'ID': 5, 'Produto': 'Mouse', 'Fabricante': 'Dell', 'Garantia': '2030-05-04', 'Valor': '100,50'},\n",
        "    {'ID': 6, 'Produto': 'Headphone', 'Fabricante': 'Dell', 'Garantia': '2030-05-04', 'Valor': '320,15'},\n",
        "    {'ID': 7, 'Produto': 'SSD 1TB', 'Fabricante': 'Dell', 'Garantia': '2030-05-04', 'Valor': '759,99'},\n",
        "]\n",
        "\n",
        "df1 = spark.createDataFrame(meus_produtos)\n",
        "\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp_dI5OuxOFk",
        "outputId": "38838874-fba7-4d78-f0e8-4689b5134deb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+---+----------------+-------+\n",
            "|Fabricante|  Garantia| ID|         Produto|  Valor|\n",
            "+----------+----------+---+----------------+-------+\n",
            "|      Dell|2030-05-04|  1|        Notebook|4200,99|\n",
            "|      Dell|2030-05-04|  2|         Monitor| 750,29|\n",
            "|      Dell|2030-05-04|  3|Memoria Ram 16GB| 200,00|\n",
            "|      Dell|2030-05-04|  4|         Teclado| 350,27|\n",
            "|      Dell|2030-05-04|  5|           Mouse| 100,50|\n",
            "|      Dell|2030-05-04|  6|       Headphone| 320,15|\n",
            "|      Dell|2030-05-04|  7|         SSD 1TB| 759,99|\n",
            "+----------+----------+---+----------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekWmzrUYw3oO",
        "outputId": "0bf0f17a-f8f8-4ccf-e6f4-e5002c0e69f9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Fabricante: string (nullable = true)\n",
            " |-- Garantia: date (nullable = true)\n",
            " |-- ID: long (nullable = true)\n",
            " |-- Produto: string (nullable = true)\n",
            " |-- Valor: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convertendo** **string** **para** **float**"
      ],
      "metadata": {
        "id": "D57dcJGGxFOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import DoubleType as dt\n",
        "from pyspark.sql.types import StringType as st\n",
        "from pyspark.sql import functions as f\n",
        "\n",
        "df1 = df1\\\n",
        ".withColumn('Garantia', f.to_date(df1.Garantia.cast(st()),'yyyy-MM-dd'))\n",
        "\n",
        "df1 = df1\\\n",
        ".withColumn('Valor', f.regexp_replace('Valor', ',', '.')) \n",
        "\n",
        "#coluna q eu quero alterar | oq eu quero subistuir | por oq eu vou substituir"
      ],
      "metadata": {
        "id": "sty7gC72xJ4l"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.withColumn('Valor', df1['Valor'].cast(dt()))"
      ],
      "metadata": {
        "id": "bZBUiopBzZv3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando uma sessão no spark"
      ],
      "metadata": {
        "id": "2rKsJzv652Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spark = SparkSession.builder\\\n",
        "# .master('local[*]')\\\n",
        "#  .appName('Meu App Spark')\\\n",
        "#  .getOrCreate()"
      ],
      "metadata": {
        "id": "V207ZUX-7Q-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').appName('Meu App Spark').getOrCreate()"
      ],
      "metadata": {
        "id": "5SRJNhfJ51zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando um dataset"
      ],
      "metadata": {
        "id": "2meb5_T29Fj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = spark.read.csv('/content/sample_data/california_housing_test.csv', inferSchema=True, header=True)"
      ],
      "metadata": {
        "id": "X7FiJkCF9NgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printando o schema"
      ],
      "metadata": {
        "id": "TZq_hLfT-I3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.printSchema()"
      ],
      "metadata": {
        "id": "ZJcocb_7-LsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encerrar a sessão"
      ],
      "metadata": {
        "id": "IlwoLni8-jRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "STDBcFlC-lB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}